{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# أساسيات بايتورتش للديب ليرننق"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- نوشن: https://www.notion.so/19ac66537749806cacd6db749955e8c7?v=19ac6653774981bf9d0e000cda83898f&pvs=4\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version is: 2.5.1+cu118\n",
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "CUDA Capability: (8, 9)\n",
      "Total Memory: 8.585216 GB\n",
      "Memory Allocated: 3.584e-06 GB\n",
      "Memory Cached: 0.002097152 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"Torch version is: {torch.__version__ }\")\n",
    "\n",
    "cuda0 = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {cuda0}\")\n",
    "\n",
    "if cuda0 == \"cuda\":\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Capability: {torch.cuda.get_device_capability(0)}\")\n",
    "    print(f\"Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9} GB\")\n",
    "    print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / 1e9} GB\")\n",
    "    print(f\"Memory Cached: {torch.cuda.memory_reserved(0) / 1e9} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors, what Tensors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## PyTorch Fundementals for DL by https://github.com/mrdbourke , you can also find our Notion notebook on:\n",
    "# https://www.notion.so/19ac66537749806cacd6db749955e8c7?v=19ac6653774981bf9d0e000cda83898f&pvs=4\n",
    "# feel free to tag along and learn with us!\n",
    "\n",
    "\n",
    "# Example tensor\n",
    "tensor = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# Move tensor to the GPU if available\n",
    "tensor = tensor.to(cuda0)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "مقدمة: ماهو تنسور؟ مازلت تتذكر فيه من النوشن بووك؟\n",
    "خليني نذكرك: تنسور هو طريقة تمثيل الداتا"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "وتوا حنديرو عمليات الأساسية على كل انواع التنسورز\n",
    "1. سكيلر\n",
    "2. متجه\n",
    "3. مصفوفة\n",
    "\n",
    "صفات التنسور:\n",
    "\n",
    "شكله tensor.shape\n",
    "\n",
    "حجمه tensor.size\n",
    "\n",
    "tensor.ndim أبعاده\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7])\n",
      " Scalar shape: torch.Size([1])\n",
      " Scalar Size: <built-in method size of Tensor object at 0x000002038F22FCC0>\n",
      " Number of Dimensions: 1\n",
      " Scalar items: 7\n",
      " Scalar datatype: torch.int64\n",
      " Scalar on device: cpu\n",
      " newScalar on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Tensor: Scalar\n",
    "\n",
    "scalar = torch.tensor([7])\n",
    "print(scalar)\n",
    "print(f\" Scalar shape: {scalar.shape}\") #shape\n",
    "print(f\" Scalar Size: {scalar.size}\") #size\n",
    "print(f\" Number of Dimensions: {scalar.ndim}\") #ndim\n",
    "\n",
    "newScalar = torch.tensor(7, device = cuda0) #on GPU :)\n",
    "print(f\" Scalar items: {scalar.item()}\")\n",
    "print(f\" Scalar datatype: {scalar.dtype}\")\n",
    "print(f\" Scalar on device: {scalar.device}\") # do , device = device , we initialized it earlier to have a cuda\n",
    "print(f\" newScalar on device: {newScalar.device}\") # do , device = device , we initialized it earlier to have a cuda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Vector: tensor([7, 7])\n",
      "GPU Vector: tensor([7, 7], device='cuda:0')\n",
      "\n",
      "CPU Vector Device: cpu\n",
      "GPU Vector Device: cuda:0\n",
      "\n",
      "CPU Vector Shape: torch.Size([2])\n",
      "GPU Vector Shape: torch.Size([2])\n",
      "\n",
      "CPU Vector Datatype: torch.int64\n",
      "GPU Vector Datatype: torch.int64\n",
      "\n",
      "CPU Vector Size: torch.Size([2])\n",
      "GPU Vector Size: torch.Size([2])\n",
      "\n",
      "CPU Vector Dimension: 1\n",
      "GPU Vector Dimension: 1\n",
      "\n",
      "CPU Vector nDimension: 1\n",
      "GPU Vector nDimension: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tensor: Vector متجه\n",
    "cpu_vector = torch.tensor([7, 7])\n",
    "gpu_vector = cpu_vector.to(cuda0)\n",
    "\n",
    "print(f\"CPU Vector: {cpu_vector}\")\n",
    "print(f\"GPU Vector: {gpu_vector}\\n\")\n",
    "\n",
    "print(f\"CPU Vector Device: {cpu_vector.device}\")\n",
    "print(f\"GPU Vector Device: {gpu_vector.device}\\n\")\n",
    "\n",
    "print(f\"CPU Vector Shape: {cpu_vector.shape}\")\n",
    "print(f\"GPU Vector Shape: {gpu_vector.shape}\\n\")\n",
    "\n",
    "print(f\"CPU Vector Datatype: {cpu_vector.dtype}\") #defualt int64\n",
    "print(f\"GPU Vector Datatype: {gpu_vector.dtype}\\n\")\n",
    "\n",
    "print(f\"CPU Vector Size: {cpu_vector.size()}\")\n",
    "print(f\"GPU Vector Size: {gpu_vector.size()}\\n\")\n",
    "\n",
    "print(f\"CPU Vector Dimension: {cpu_vector.dim()}\")\n",
    "print(f\"GPU Vector Dimension: {gpu_vector.dim()}\\n\")\n",
    "\n",
    "print(f\"CPU Vector nDimension: {cpu_vector.ndim}\")\n",
    "print(f\"GPU Vector nDimension: {gpu_vector.ndim}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATRIX Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU MATRIX Shape: torch.Size([2, 2])\n",
      "GPU MATRIX Shape: torch.Size([2, 2])\n",
      "\n",
      "CPU MATRIX size: <built-in method size of Tensor object at 0x000002038F24E310>\n",
      "GPU MATRIX size: <built-in method size of Tensor object at 0x000002038F00B270>\n",
      "\n",
      "CPU MATRIX datatype: torch.int64\n",
      "GPU MATRIX datatype: torch.int64\n",
      "\n",
      "CPU MATRIX dimensions: 2\n",
      "GPU MATRIX dimensions: 2\n",
      "\n",
      "CPU MAtrix nDimensions: 2\n",
      "GPU MAtrix nDimensions: 2\n",
      "\n",
      "CPU MATRIX device: cpu\n",
      "GPU MATRIX device: cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#MATRIX\n",
    "\n",
    "cpu_MATRIX = torch.tensor([[7, 8],\n",
    "                       [9, 10]])\n",
    "gpu_MATRIX = torch.tensor([[7, 8],\n",
    "                       [9, 10]], device = cuda0)\n",
    "\n",
    "print(f\"CPU MATRIX Shape: {cpu_MATRIX.shape}\")\n",
    "print(f\"GPU MATRIX Shape: {gpu_MATRIX.shape}\\n\")\n",
    "\n",
    "print(f\"CPU MATRIX size: {cpu_MATRIX.size}\")\n",
    "print(f\"GPU MATRIX size: {gpu_MATRIX.size}\\n\")\n",
    "\n",
    "print(f\"CPU MATRIX datatype: {cpu_MATRIX.dtype}\")\n",
    "print(f\"GPU MATRIX datatype: {gpu_MATRIX.dtype}\\n\")\n",
    "\n",
    "print(f\"CPU MATRIX dimensions: {cpu_MATRIX.dim()}\")\n",
    "print(f\"GPU MATRIX dimensions: {gpu_MATRIX.dim()}\\n\")\n",
    "\n",
    "print(f\"CPU MAtrix nDimensions: {cpu_MATRIX.ndim}\")\n",
    "print(f\"GPU MAtrix nDimensions: {gpu_MATRIX.ndim}\\n\")\n",
    "\n",
    "print(f\"CPU MATRIX device: {cpu_MATRIX.device}\")\n",
    "print(f\"GPU MATRIX device: {gpu_MATRIX.device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TENSOR\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]]], device = cuda0)\n",
    "TENSOR.ndim #ndim = number of dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Random Tensor: \n",
      "tensor([[[0.5622, 0.4116],\n",
      "         [0.5736, 0.8218]],\n",
      "\n",
      "        [[0.8165, 0.4656],\n",
      "         [0.8148, 0.6257]],\n",
      "\n",
      "        [[0.0344, 0.5809],\n",
      "         [0.9565, 0.7587]],\n",
      "\n",
      "        [[0.1610, 0.4673],\n",
      "         [0.6245, 0.6116]],\n",
      "\n",
      "        [[0.6286, 0.6669],\n",
      "         [0.1803, 0.5619]],\n",
      "\n",
      "        [[0.9868, 0.8454],\n",
      "         [0.8841, 0.6960]],\n",
      "\n",
      "        [[0.2774, 0.0473],\n",
      "         [0.7853, 0.1444]],\n",
      "\n",
      "        [[0.4443, 0.5686],\n",
      "         [0.6492, 0.3484]],\n",
      "\n",
      "        [[0.6636, 0.0972],\n",
      "         [0.2026, 0.8807]],\n",
      "\n",
      "        [[0.3339, 0.3142],\n",
      "         [0.4543, 0.0762]]])\n",
      "\n",
      "GPU Random Tensor: \n",
      "tensor([[[0.5622, 0.4116],\n",
      "         [0.5736, 0.8218]],\n",
      "\n",
      "        [[0.8165, 0.4656],\n",
      "         [0.8148, 0.6257]],\n",
      "\n",
      "        [[0.0344, 0.5809],\n",
      "         [0.9565, 0.7587]],\n",
      "\n",
      "        [[0.1610, 0.4673],\n",
      "         [0.6245, 0.6116]],\n",
      "\n",
      "        [[0.6286, 0.6669],\n",
      "         [0.1803, 0.5619]],\n",
      "\n",
      "        [[0.9868, 0.8454],\n",
      "         [0.8841, 0.6960]],\n",
      "\n",
      "        [[0.2774, 0.0473],\n",
      "         [0.7853, 0.1444]],\n",
      "\n",
      "        [[0.4443, 0.5686],\n",
      "         [0.6492, 0.3484]],\n",
      "\n",
      "        [[0.6636, 0.0972],\n",
      "         [0.2026, 0.8807]],\n",
      "\n",
      "        [[0.3339, 0.3142],\n",
      "         [0.4543, 0.0762]]], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_cpu_tensor = torch.rand(10, 2, 2)\n",
    "random_gpu_tensor = random_cpu_tensor.to(cuda0)\n",
    "\n",
    "print(f\"CPU Random Tensor: \\n{random_cpu_tensor}\\n\")\n",
    "print(f\"GPU Random Tensor: \\n{random_gpu_tensor}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a random tensor similar to image tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([244, 244, 3]), 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_img_tensor = torch.rand(size=(244,244,3))\n",
    "cpu_img_tensor.shape, cpu_img_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors in Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1273, 0.2793, 0.0280, 0.4550, 0.6594],\n",
      "         [0.7914, 0.0734, 0.2115, 0.2421, 0.8224],\n",
      "         [0.5137, 0.6655, 0.3164, 0.5670, 0.7936],\n",
      "         [0.5205, 0.7854, 0.3050, 0.0476, 0.4286],\n",
      "         [0.7231, 0.7995, 0.5213, 0.5170, 0.4910]],\n",
      "\n",
      "        [[0.8778, 0.1518, 0.5896, 0.6126, 0.3451],\n",
      "         [0.9404, 0.0570, 0.2876, 0.9616, 0.8478],\n",
      "         [0.8833, 0.5802, 0.1597, 0.7284, 0.5452],\n",
      "         [0.0974, 0.1001, 0.9864, 0.3888, 0.6594],\n",
      "         [0.2107, 0.3714, 0.8695, 0.2428, 0.2407]],\n",
      "\n",
      "        [[0.5560, 0.1503, 0.5724, 0.5835, 0.5845],\n",
      "         [0.6849, 0.6989, 0.5027, 0.5485, 0.0170],\n",
      "         [0.4222, 0.6897, 0.7067, 0.5147, 0.2698],\n",
      "         [0.6923, 0.2527, 0.7509, 0.1334, 0.8540],\n",
      "         [0.1541, 0.2395, 0.5380, 0.2964, 0.6073]],\n",
      "\n",
      "        [[0.0012, 0.5028, 0.1972, 0.6776, 0.5822],\n",
      "         [0.0585, 0.2196, 0.4931, 0.1278, 0.0930],\n",
      "         [0.1269, 0.5565, 0.4606, 0.8920, 0.0436],\n",
      "         [0.0193, 0.6907, 0.8510, 0.4378, 0.1691],\n",
      "         [0.0392, 0.1595, 0.7757, 0.5873, 0.7573]],\n",
      "\n",
      "        [[0.1409, 0.2315, 0.9384, 0.9149, 0.9043],\n",
      "         [0.1716, 0.1806, 0.2216, 0.1881, 0.0185],\n",
      "         [0.3675, 0.7773, 0.7637, 0.9744, 0.9033],\n",
      "         [0.9279, 0.8213, 0.5844, 0.5392, 0.4773],\n",
      "         [0.7788, 0.0442, 0.1212, 0.9316, 0.7516]]])\n",
      "tensor([[[0.0945, 0.5131, 0.1191, 0.4847, 0.9375],\n",
      "         [0.3693, 0.9936, 0.6867, 0.6171, 0.0143],\n",
      "         [0.1034, 0.5323, 0.5762, 0.4921, 0.2203],\n",
      "         [0.8264, 0.1933, 0.0701, 0.2136, 0.3262],\n",
      "         [0.4855, 0.0658, 0.7058, 0.1868, 0.9719]],\n",
      "\n",
      "        [[0.2976, 0.0095, 0.7885, 0.6892, 0.3816],\n",
      "         [0.1893, 0.8239, 0.8610, 0.8882, 0.2673],\n",
      "         [0.1109, 0.3964, 0.0230, 0.8939, 0.3424],\n",
      "         [0.7883, 0.9054, 0.0997, 0.5919, 0.9322],\n",
      "         [0.1543, 0.6638, 0.2876, 0.1110, 0.4885]],\n",
      "\n",
      "        [[0.2754, 0.9578, 0.0967, 0.8631, 0.3034],\n",
      "         [0.7545, 0.9002, 0.7745, 0.1510, 0.9767],\n",
      "         [0.5161, 0.7738, 0.5728, 0.3251, 0.9071],\n",
      "         [0.9241, 0.7908, 0.1114, 0.9383, 0.6842],\n",
      "         [0.3951, 0.5583, 0.2072, 0.8507, 0.9554]],\n",
      "\n",
      "        [[0.8904, 0.5895, 0.5402, 0.6793, 0.3175],\n",
      "         [0.0246, 0.9895, 0.3458, 0.7525, 0.9088],\n",
      "         [0.7106, 0.8062, 0.5278, 0.6360, 0.3173],\n",
      "         [0.9873, 0.0996, 0.4200, 0.0515, 0.2860],\n",
      "         [0.8317, 0.1271, 0.0055, 0.9885, 0.4578]],\n",
      "\n",
      "        [[0.4133, 0.4628, 0.4617, 0.6962, 0.7373],\n",
      "         [0.8658, 0.3880, 0.9025, 0.0849, 0.0832],\n",
      "         [0.6977, 0.0980, 0.6898, 0.6631, 0.1192],\n",
      "         [0.0331, 0.7974, 0.0726, 0.1553, 0.9350],\n",
      "         [0.9426, 0.9866, 0.8630, 0.3978, 0.8985]]], device='cuda:0')\n",
      "rand CPU Tensor size: \n",
      " torch.Size([5, 5, 5])\n",
      "\n",
      "rand GPU Tensor size: \n",
      " torch.Size([5, 5, 5])\n",
      "\n",
      "rand CPU Tensor shape: \n",
      " torch.Size([5, 5, 5])\n",
      "\n",
      "rand GPU Tensor shape: \n",
      " torch.Size([5, 5, 5])\n",
      "\n",
      "rand CPU Tensor nDimensions: \n",
      " 3\n",
      "\n",
      "rand GPU Tensor nDimensions: \n",
      " 3\n",
      "\n",
      "Multiply random CPU tensor with random GPU tensor, \n",
      "result:\n",
      "tensor([[[1.6199e-02, 7.8020e-02, 7.8192e-04, 2.0699e-01, 4.3482e-01],\n",
      "         [6.2628e-01, 5.3900e-03, 4.4752e-02, 5.8630e-02, 6.7631e-01],\n",
      "         [2.6390e-01, 4.4289e-01, 1.0009e-01, 3.2150e-01, 6.2974e-01],\n",
      "         [2.7094e-01, 6.1686e-01, 9.3025e-02, 2.2683e-03, 1.8369e-01],\n",
      "         [5.2289e-01, 6.3927e-01, 2.7174e-01, 2.6728e-01, 2.4109e-01]],\n",
      "\n",
      "        [[7.7060e-01, 2.3041e-02, 3.4768e-01, 3.7528e-01, 1.1909e-01],\n",
      "         [8.8437e-01, 3.2477e-03, 8.2732e-02, 9.2472e-01, 7.1881e-01],\n",
      "         [7.8023e-01, 3.3666e-01, 2.5513e-02, 5.3052e-01, 2.9724e-01],\n",
      "         [9.4878e-03, 1.0017e-02, 9.7296e-01, 1.5119e-01, 4.3484e-01],\n",
      "         [4.4400e-02, 1.3796e-01, 7.5598e-01, 5.8957e-02, 5.7925e-02]],\n",
      "\n",
      "        [[3.0917e-01, 2.2577e-02, 3.2763e-01, 3.4042e-01, 3.4163e-01],\n",
      "         [4.6912e-01, 4.8845e-01, 2.5268e-01, 3.0088e-01, 2.8889e-04],\n",
      "         [1.7823e-01, 4.7571e-01, 4.9940e-01, 2.6495e-01, 7.2767e-02],\n",
      "         [4.7923e-01, 6.3869e-02, 5.6379e-01, 1.7787e-02, 7.2932e-01],\n",
      "         [2.3753e-02, 5.7372e-02, 2.8945e-01, 8.7878e-02, 3.6882e-01]],\n",
      "\n",
      "        [[1.3350e-06, 2.5282e-01, 3.8905e-02, 4.5913e-01, 3.3898e-01],\n",
      "         [3.4240e-03, 4.8219e-02, 2.4311e-01, 1.6326e-02, 8.6431e-03],\n",
      "         [1.6110e-02, 3.0970e-01, 2.1218e-01, 7.9558e-01, 1.9014e-03],\n",
      "         [3.7133e-04, 4.7712e-01, 7.2420e-01, 1.9171e-01, 2.8584e-02],\n",
      "         [1.5356e-03, 2.5452e-02, 6.0176e-01, 3.4497e-01, 5.7345e-01]],\n",
      "\n",
      "        [[1.9839e-02, 5.3615e-02, 8.8052e-01, 8.3704e-01, 8.1775e-01],\n",
      "         [2.9438e-02, 3.2604e-02, 4.9127e-02, 3.5384e-02, 3.4174e-04],\n",
      "         [1.3505e-01, 6.0422e-01, 5.8323e-01, 9.4945e-01, 8.1598e-01],\n",
      "         [8.6094e-01, 6.7457e-01, 3.4156e-01, 2.9070e-01, 2.2781e-01],\n",
      "         [6.0651e-01, 1.9546e-03, 1.4677e-02, 8.6787e-01, 5.6497e-01]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_cpu_TENSOR = torch.rand(5, 5, 5)\n",
    "rand_gpu_TENSOR = torch.rand(5, 5, 5, device = cuda0)\n",
    "\n",
    "print(rand_cpu_TENSOR)\n",
    "print(rand_gpu_TENSOR)\n",
    "\n",
    "print(f\"rand CPU Tensor size: \\n {rand_cpu_TENSOR.size()}\\n\")\n",
    "print(f\"rand GPU Tensor size: \\n {rand_gpu_TENSOR.size()}\\n\")\n",
    "\n",
    "print(f\"rand CPU Tensor shape: \\n {rand_cpu_TENSOR.shape}\\n\")\n",
    "print(f\"rand GPU Tensor shape: \\n {rand_gpu_TENSOR.shape}\\n\")\n",
    "\n",
    "print(f\"rand CPU Tensor nDimensions: \\n {rand_cpu_TENSOR.ndim}\\n\")\n",
    "print(f\"rand GPU Tensor nDimensions: \\n {rand_gpu_TENSOR.ndim}\\n\")\n",
    "\n",
    "mult = torch.mul(rand_cpu_TENSOR, rand_cpu_TENSOR) #can't multiply tensosrs on different devices\n",
    "#and in different dimensions\n",
    "print(f\"Multiply random CPU tensor with random GPU tensor, \\nresult:\\n{mult}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "print(torch.arange(start=0,step=1,dtype=torch.int64,end=12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutiply: tensor([70, 70])\n",
      "Add: tensor([107, 107])\n",
      "Subtract: tensor([0, 0])\n",
      "Divide: tensor([1., 1.])\n",
      "Exponent: tensor([49, 49])\n",
      "Modulus: tensor([2, 2])\n",
      "Dot product: 98\n"
     ]
    }
   ],
   "source": [
    "cpu_vector = torch.tensor([7, 7])\n",
    "\n",
    "print(f\"Mutiply: {cpu_vector*10}\") #70\n",
    "print(f\"Add: {cpu_vector+100}\") #107\n",
    "print(f\"Subtract: {cpu_vector-7}\") #0\n",
    "print(f\"Divide: {cpu_vector/7}\") #1\n",
    "print(f\"Exponent: {cpu_vector**2}\") #49\n",
    "print(f\"Modulus: {cpu_vector%5}\") #2\n",
    "print(f\"Dot product: {torch.dot(cpu_vector, cpu_vector)}\") #49\n",
    "#print(f\"Cross product: {torch.cross(cpu_vector, cpu_vector)}\") #0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying 2 matrices:\n",
    "- Element wise multiplication\n",
    "- Matrix mult which is called dot product\n",
    "\n",
    "Feel free to go over the basics of matrices and Linear algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3]) * tensor([1, 2, 3]) = tensor([1, 4, 9])\n",
      "torch.mult(temp_tensor, temp_tensor) =  tensor(14)\n"
     ]
    }
   ],
   "source": [
    "temp_tensor = torch.tensor([1, 2, 3])\n",
    "print(temp_tensor)\n",
    "\n",
    "print(temp_tensor, \"*\", temp_tensor ,\"=\" , temp_tensor*temp_tensor)\n",
    "\n",
    "print(\"torch.mult(temp_tensor, temp_tensor) = \", torch.matmul(temp_tensor, temp_tensor))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what is the difference between the 2 multiplications?\n",
    "dot product\n",
    "and\n",
    "element multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets multiply the matrices of different shapes using transpose!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix 2x3:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Transposed Matrix 2x3 (3x2):\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "\n",
      "Original Matrix 3x2:\n",
      "tensor([[ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]])\n",
      "\n",
      "Transposed Matrix 3x2 (2x3):\n",
      "tensor([[ 7,  9, 11],\n",
      "        [ 8, 10, 12]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix_2x3 = torch.tensor([[1, 2, 3],\n",
    "                           [4, 5, 6]])\n",
    "\n",
    "matrix_3x2 = torch.tensor([[7, 8],\n",
    "                           [9, 10],\n",
    "                           [11, 12]])\n",
    "\n",
    "# Transpose the matrices\n",
    "matrix_2x3_T = matrix_2x3.T\n",
    "matrix_3x2_T = matrix_3x2.T\n",
    "\n",
    "print(f\"Original Matrix 2x3:\\n{matrix_2x3}\\n\")\n",
    "print(f\"Transposed Matrix 2x3 (3x2):\\n{matrix_2x3_T}\\n\")\n",
    "\n",
    "print(f\"Original Matrix 3x2:\\n{matrix_3x2}\\n\")\n",
    "print(f\"Transposed Matrix 3x2 (2x3):\\n{matrix_3x2_T}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Errors: \n",
      " tensor([[ 58,  64],\n",
      "        [139, 154]])\n",
      "Hello Errors: \n",
      " tensor([[17, 22, 27],\n",
      "        [22, 29, 36],\n",
      "        [27, 36, 45]])\n"
     ]
    }
   ],
   "source": [
    "#                                         2             2     \n",
    "print(\"Hello Errors: \\n\", torch.mm(matrix_2x3, matrix_3x2))\n",
    "print(\"Hello Errors: \\n\", torch.mm(matrix_2x3.T, matrix_2x3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = torch.tensor([[1, 2],\n",
    "                         [3, 4]])\n",
    "\n",
    "tensor_b = torch.tensor([[5, 6, 7],\n",
    "                         [8, 9, 10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors Aggregation\n",
    "- Min\n",
    "- Max\n",
    "- Mean\n",
    "- Sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum is:  tensor(1) \n",
      "location:  tensor(0)\n",
      "Maximum is:  tensor(100) \n",
      "location:  tensor(18) \n",
      "\n",
      "Mean is:  tensor(31.3158) \n",
      "notice that we needed to convert it to float get the mean\n",
      "of type:  torch.LongTensor\n",
      "tensor([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  20.,  30.,\n",
      "         40.,  50.,  60.,  70.,  80.,  90., 100.])\n"
     ]
    }
   ],
   "source": [
    "temp_tensor = torch.tensor([1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100])\n",
    "print(\"Minimum is: \",torch.min(temp_tensor),\"\\nlocation: \" ,torch.argmin(temp_tensor)) # -> 1\n",
    "print(\"Maximum is: \", torch.max(temp_tensor), \"\\nlocation: \", torch.argmax(temp_tensor),\"\\n\") # -> 100\n",
    "print(\"Mean is: \",torch.mean(temp_tensor.type(torch.float32)), \"\\nnotice that we needed to convert it to float get the mean\") # -> 31.3158\n",
    "print(\"of type: \",temp_tensor.type()) # -> torch.LongTensor\n",
    "print(temp_tensor.type(torch.float32)) # -> torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(595)\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(temp_tensor)) # -> 595"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Sculpture :)\n",
    "- Reshaping\n",
    "- Stacking\n",
    "- Squeezing / unSqueezing\n",
    "- View\n",
    "- Stacking , Vertical Stacking & Horizontal Sacking\n",
    "- Permute: Swap Dimensions in a certain way\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0,100,1)\n",
    "x\n",
    "x.reshape(5,20)\n",
    "x.size()\n",
    "#x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 Random Matrices:\n",
      "Matrix 1:\n",
      "tensor([[0.5619, 0.7763, 0.6536],\n",
      "        [0.4909, 0.7916, 0.4193]])\n",
      "\n",
      "Matrix 2:\n",
      "tensor([[0.6917, 0.3214, 0.1560],\n",
      "        [0.0827, 0.3290, 0.1687]])\n",
      "\n",
      "Matrix 3:\n",
      "tensor([[0.8844, 0.6342, 0.8976],\n",
      "        [0.3718, 0.0898, 0.8400]])\n",
      "\n",
      "Matrix 4:\n",
      "tensor([[0.2083, 0.9601, 0.3186],\n",
      "        [0.5770, 0.5245, 0.1595]])\n",
      "\n",
      "Matrix 5:\n",
      "tensor([[0.5237, 0.7494, 0.9080],\n",
      "        [0.2149, 0.4734, 0.4034]])\n",
      "\n",
      "Horizontal Stack of the 5 Random Matrices:\n",
      "tensor([[0.5619, 0.7763, 0.6536, 0.6917, 0.3214, 0.1560, 0.8844, 0.6342, 0.8976,\n",
      "         0.2083, 0.9601, 0.3186, 0.5237, 0.7494, 0.9080],\n",
      "        [0.4909, 0.7916, 0.4193, 0.0827, 0.3290, 0.1687, 0.3718, 0.0898, 0.8400,\n",
      "         0.5770, 0.5245, 0.1595, 0.2149, 0.4734, 0.4034]])\n",
      "\n",
      "Vertical Stack of the 5 Random Matrices:\n",
      "tensor([[0.5619, 0.7763, 0.6536],\n",
      "        [0.4909, 0.7916, 0.4193],\n",
      "        [0.6917, 0.3214, 0.1560],\n",
      "        [0.0827, 0.3290, 0.1687],\n",
      "        [0.8844, 0.6342, 0.8976],\n",
      "        [0.3718, 0.0898, 0.8400],\n",
      "        [0.2083, 0.9601, 0.3186],\n",
      "        [0.5770, 0.5245, 0.1595],\n",
      "        [0.5237, 0.7494, 0.9080],\n",
      "        [0.2149, 0.4734, 0.4034]])\n",
      "\n",
      "Using .Stack function with dim=0:\n",
      "\n",
      "tensor([[[0.5619, 0.7763, 0.6536],\n",
      "         [0.4909, 0.7916, 0.4193]],\n",
      "\n",
      "        [[0.6917, 0.3214, 0.1560],\n",
      "         [0.0827, 0.3290, 0.1687]],\n",
      "\n",
      "        [[0.8844, 0.6342, 0.8976],\n",
      "         [0.3718, 0.0898, 0.8400]],\n",
      "\n",
      "        [[0.2083, 0.9601, 0.3186],\n",
      "         [0.5770, 0.5245, 0.1595]],\n",
      "\n",
      "        [[0.5237, 0.7494, 0.9080],\n",
      "         [0.2149, 0.4734, 0.4034]]])\n",
      "\n",
      "Using .Stack function with dim=1:\n",
      "\n",
      "tensor([[[0.5619, 0.7763, 0.6536],\n",
      "         [0.6917, 0.3214, 0.1560],\n",
      "         [0.8844, 0.6342, 0.8976],\n",
      "         [0.2083, 0.9601, 0.3186],\n",
      "         [0.5237, 0.7494, 0.9080]],\n",
      "\n",
      "        [[0.4909, 0.7916, 0.4193],\n",
      "         [0.0827, 0.3290, 0.1687],\n",
      "         [0.3718, 0.0898, 0.8400],\n",
      "         [0.5770, 0.5245, 0.1595],\n",
      "         [0.2149, 0.4734, 0.4034]]])\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 random matrices\n",
    "random_matrices = [torch.rand(2, 3) for _ in range(5)]\n",
    "\n",
    "# Stack matrices horizontally\n",
    "horizontal_stack = torch.hstack(random_matrices)\n",
    "\n",
    "# Stack matrices vertically\n",
    "vertical_stack = torch.vstack(random_matrices)\n",
    "\n",
    "print(\"Generated 5 Random Matrices:\")\n",
    "for i, matrix in enumerate(random_matrices):\n",
    "    print(f\"Matrix {i+1}:\\n{matrix}\\n\")\n",
    "\n",
    "print(\"Horizontal Stack of the 5 Random Matrices:\")\n",
    "print(horizontal_stack)\n",
    "\n",
    "print(\"\\nVertical Stack of the 5 Random Matrices:\")\n",
    "print(vertical_stack)\n",
    "\n",
    "print(\"\\nUsing .Stack function with dim=0:\\n\") #at position 0\n",
    "print(torch.stack(random_matrices, dim=0)) # -> 5x2x3\n",
    "\n",
    "print(\"\\nUsing .Stack function with dim=1:\\n\") #at position 1\n",
    "print(torch.stack(random_matrices, dim=1))# -> 2x5x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeezing Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Squeezed Tensor:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]], device='cuda:0')\n",
      "\n",
      "UnSqueezed Tensor:\n",
      " tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]], device='cuda:0')\n",
      "\n",
      "Vertical Stack:\n",
      " tensor([[7, 7],\n",
      "        [7, 7]])\n",
      "\n",
      "Horizontal Stack:\n",
      " tensor([7, 7, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "# Squeezing\n",
    "# Remove single-dimensional entries from the shape of 'TENSOR'\n",
    "squeezed_tensor = TENSOR.squeeze()\n",
    "print(\"\\nSqueezed Tensor:\\n\", squeezed_tensor)\n",
    "\n",
    "# UnSqueezing\n",
    "# Add a single-dimensional entry to the shape of 'squeezed_tensor'\n",
    "unsqueezed_tensor = squeezed_tensor.unsqueeze(0)\n",
    "print(\"\\nUnSqueezed Tensor:\\n\", unsqueezed_tensor)\n",
    "\n",
    "\n",
    "# Stacking, Vertical Stacking & Horizontal Stacking\n",
    "# Stack 'cpu_vector' vertically and horizontally\n",
    "vertical_stack = torch.vstack((cpu_vector, cpu_vector))\n",
    "horizontal_stack = torch.hstack((cpu_vector, cpu_vector))\n",
    "print(\"\\nVertical Stack:\\n\", vertical_stack)\n",
    "print(\"\\nHorizontal Stack:\\n\", horizontal_stack)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Viewed Tensor (2x5x10):\n",
      " tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "         [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "         [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
      "         [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n",
      "\n",
      "        [[50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
      "         [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
      "         [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
      "         [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
      "         [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# View\n",
    "# Change the view of 'reshaped_tensor' to a 2x5x10 tensor\n",
    "reshaped_tensor = torch.arange(0, 100)\n",
    "viewed_tensor = reshaped_tensor.view(2, 5, 10) # -> 2 Matrices, 5 Rows and 10 Columns each\n",
    "print(\"\\nViewed Tensor (2x5x10):\\n\", viewed_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permute Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Permuted Tensor (Swapped Dimensions):\n",
      " tensor([[[9.0245e-01, 6.9792e-01, 8.5409e-01,  ..., 5.1611e-01,\n",
      "          6.9189e-01, 2.5989e-01],\n",
      "         [2.2769e-01, 4.3870e-01, 3.3006e-01,  ..., 1.0962e-01,\n",
      "          5.9821e-01, 6.2123e-01],\n",
      "         [8.1056e-01, 9.3157e-01, 5.2493e-01,  ..., 5.3297e-02,\n",
      "          1.1896e-01, 1.6134e-01],\n",
      "         ...,\n",
      "         [4.3832e-01, 7.6814e-01, 7.4798e-01,  ..., 2.6368e-01,\n",
      "          3.5422e-01, 5.6247e-01],\n",
      "         [6.5018e-01, 6.2464e-01, 4.7184e-01,  ..., 9.1836e-01,\n",
      "          1.7395e-01, 7.9691e-01],\n",
      "         [5.0237e-02, 1.8236e-01, 4.3364e-01,  ..., 6.4957e-01,\n",
      "          1.5362e-01, 5.0605e-01]],\n",
      "\n",
      "        [[2.9680e-01, 3.7585e-01, 4.6269e-01,  ..., 8.1825e-01,\n",
      "          7.4324e-01, 7.7889e-01],\n",
      "         [3.3540e-01, 8.7558e-01, 3.6492e-02,  ..., 7.8436e-01,\n",
      "          1.0729e-01, 7.5248e-01],\n",
      "         [4.0639e-01, 4.5671e-01, 2.9442e-01,  ..., 2.0778e-01,\n",
      "          5.9588e-01, 3.6297e-01],\n",
      "         ...,\n",
      "         [7.6230e-01, 1.0581e-01, 1.3056e-01,  ..., 5.4666e-01,\n",
      "          8.3908e-02, 2.0349e-01],\n",
      "         [7.1087e-01, 5.4677e-01, 3.9039e-01,  ..., 7.2144e-02,\n",
      "          1.8050e-01, 7.9480e-02],\n",
      "         [5.4581e-01, 3.3050e-01, 5.4338e-01,  ..., 9.6976e-01,\n",
      "          1.8957e-01, 2.4660e-01]],\n",
      "\n",
      "        [[7.4500e-01, 5.3914e-01, 8.6853e-01,  ..., 9.9360e-01,\n",
      "          1.8607e-01, 5.0240e-01],\n",
      "         [4.7638e-01, 4.9899e-01, 9.4719e-01,  ..., 4.5304e-01,\n",
      "          7.4407e-01, 5.8498e-01],\n",
      "         [6.5936e-01, 8.0312e-01, 7.4404e-04,  ..., 9.1156e-01,\n",
      "          8.7266e-01, 6.1014e-01],\n",
      "         ...,\n",
      "         [7.5377e-01, 6.5121e-01, 2.5814e-01,  ..., 5.6800e-02,\n",
      "          8.7043e-01, 8.9405e-01],\n",
      "         [4.5617e-01, 1.6608e-01, 4.8793e-01,  ..., 2.7661e-01,\n",
      "          7.5071e-01, 7.9354e-01],\n",
      "         [4.1501e-01, 8.0692e-01, 5.3613e-01,  ..., 9.0279e-01,\n",
      "          7.1263e-01, 2.7975e-01]]])\n"
     ]
    }
   ],
   "source": [
    "# Permute: Swap Dimensions in a certain way\n",
    "# Change the order of dimensions of 'cpu_img_tensor'\n",
    "permuted_tensor = cpu_img_tensor.permute(2, 0, 1)\n",
    "print(\"\\nPermuted Tensor (Swapped Dimensions):\\n\", permuted_tensor)\n",
    "# Used with images usually :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch tensors & NumPy\n",
    "\n",
    "PyTorch can intreact with NumPy, for an example your data is in NumPy, and to do DL and ML using PyTorch -> `torch.from_numpy(ndarray)`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_AI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
